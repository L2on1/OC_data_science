{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    " - <a href=\"#C1\">Importation des données</a>\n",
    " \n",
    "**Partie 2 : Nettoyez un jeu de données**\n",
    " - <a href=\"#C2\">Nettoyez votre jeu de données</a>\n",
    " \n",
    "**Partie 3 : Représentez vos variables**\n",
    " - <a href=\"#C3\">Représentez la distribution empirique d'une variable</a>\n",
    " - <a href=\"#C4\">Présentez une variable sous forme de tableau</a>\n",
    " - <a href=\"#C5\">Découvrez les mesures de tendance centrale</a>\n",
    " - <a href=\"#C6\">Comprenez les mesures de dispersion</a>\n",
    " - <a href=\"#C7\">Appréhendez les mesures de forme</a>\n",
    " - <a href=\"#C8\">Familiarisez-vous avec les mesures de concentration</a>\n",
    " \n",
    "**Partie 4 : Réalisez une analyse bivariée**\n",
    " - <a href=\"#C9\">Analysez la corrélation entre deux variables quantitatives</a>\n",
    " - <a href=\"#C10\">Analysez deux variables quantitatives par régression linéaire</a>\n",
    " - <a href=\"#C11\">Analysez une variable quantitative et une qualitative par ANOVA</a>\n",
    " - <a href=\"#C12\">Analysez deux variables qualitatives avec le Chi-2</a>\n",
    "\n",
    "# <a name=\"C1\">Importation des données</a>\n",
    "\n",
    "Les données que nous allons utiliser tout au long de ce cours se trouvent dans le même dossier compressé où vous avez trouvé le présent notebook. Comme annoncé en préambule, c'est un fichier contenant les relevés bancaires (fictives) d'un individu. Importons dans un premier temps l'ensemble des librairies qui vont nous servir durant l'entièreté de ce cours :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons à présent charger le jeu de données, dans un dataframe que nous nommerons ici `data`. Nous affichons ensuite les 5 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('operations.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir via la commande ci dessus, nous avons 309 transactions, renseignées sur 5 variables différentes. Nous avons notamment : \n",
    "- date_operation : date de l'opération\n",
    "- libelle : libellé de l'opération\n",
    "- montant : montant de l'opération\n",
    "- solde_avt_ope : solde du compte avant l'opération considérée\n",
    "- categ : catégorie d'achat\n",
    "\n",
    "<font color='red'>*vous aurez probablement moins d'informations sur vos propres relevés bancaires. Nous avons réalisé quelques lignes de codes en amont pour ajouter la catégorie d'achat*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C2\">P2C3 - Nettoyez votre jeu de données</a>\n",
    "\n",
    "Il est à présent temps de mettre en pratique tout ce que nous avons vu sur notre jeu de données de transactions bancaires. Plusieurs **erreurs** se sont glissées dans ce jeu de données. Votre mission, si toutefois vous l'acceptez, va être de les **trouver** et de **proposer des solutions** adéquates pour les gérer.\n",
    "\n",
    "### 1. Erreurs de type\n",
    "\n",
    "Le premier reflexe devrait être de vérifier que les variables ont bien été importées dans le bon type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seule chose qui semble être problématique est la variable date qui n'est pas considérée comme une date. On peut corriger cela facilement via la fonction `to_datetime` de pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_operation'] = pd.to_datetime(data['date_operation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinon, tout semble en ordre\n",
    "\n",
    "### 2. Valeurs manquantes\n",
    "\n",
    "On va ensuite vérifier si notre jeu de données contient des valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour afficher uniquement les variables qui ont des valeurs manquantes\n",
    "nb_na = data.isnull().sum()\n",
    "nb_na[nb_na>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que notre jeu de données contient 3 valeurs manquantes. Regardons les plus en détails :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['montant'].isnull(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, il reste relativement simple de remplacer les valeurs manquantes : en effet, les transactions étant organisées par ordre chronologique, on peut à partir du solde de l'opération suivante déduire le montant qui a été débité pour chacune des ces opérations.\n",
    "\n",
    "Le montant manquant correspond donc au solde de l'opération suivante, moins le solde de l'opération concernée. Voilà comment faire cela pour nos lignes concernées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on stocke le df des valeurs manquantes dans un nouveau df\n",
    "data_na = data.loc[data['montant'].isnull(),:]\n",
    "\n",
    "# pour chaque ligne de mon df, on récupère les index (qui ne changent pas au travers du .loc)\n",
    "for index in data_na.index:\n",
    "    # calcul du montant à partir des soldes précédents et actuels\n",
    "    data.loc[index, 'montant'] = data.loc[index+1, 'solde_avt_ope'] - data.loc[index, 'solde_avt_ope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent regardons la categorie manquante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['categ'].isnull(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par manque d'informations, on devrait supprimer ici la ligne correspondante. Mais regardons si nous ne pouvons pas trouver la catégorie à partir des autres informations, notamment le libellé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['libelle'] == 'PRELEVEMENT XX TELEPHONE XX XX', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On déduit assez facilement que la catégorie manquante ici est : FACTURE TELEPHONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['categ'].isnull(), 'categ'] = 'FACTURE TELEPHONE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Doublons \n",
    "\n",
    "Regardons à présent si certaines transactions sont apparues en doublons. Pour cela, on se concentrera sur des informations qui ne peuvent normalement pas être doublés, soit : la date, le libelle, le montant et le solde avant opération. Sur ces 4 variables, il n'est normalement pas possible d'avoir deux transactions identiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[['date_operation', 'libelle', 'montant', 'solde_avt_ope']].duplicated(keep=False),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ici une opération qui est complètement en double. Il suffit donc de supprimer l'une des deux via le drop_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['date_operation', 'libelle', 'montant', 'solde_avt_ope'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Détection d'outliers :\n",
    "\n",
    "Un describe peut potentiellement nous aider dans un premier temps :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une bonne première approche en attendant d'avoir des outils plus adéquats, est de regarder le maximum et le minimum. Cela donne généralement un premier apperçu de ce qui pourrait clocher à ce niveau. Ici on voit un minimum de montant de -15 000 (ce qui correspondrait à un débit de -15000). Cela semble assez étonnant, d'autant que le solde ne semble pas descendre en conséquence à aucun moment (le max est 4700 et le minimum 1416). Vérifions les soldes autour de cette transaction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = data.loc[data['montant']==-15000,:].index[0] # récupération de l'index de la transaction à -15000\n",
    "\n",
    "data.iloc[i-1:i+2,:] # on regarde la transaction précédente et la suivante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a en effet une grosse incohérence. Les soldes nous indique une opération de -14.39 et non de -15000. Il y a en effet une valeur abérrante ici ! Remplaçons donc là pour sa valeur initiale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['montant']==-15000, 'montant'] = -14.39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données semble à présent propre, on peut avancer sur la partie analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C3\"> P3C1 - Représentez la distribution empirique d'une variable</a>\n",
    "\n",
    "**1. variables qualitatives**\n",
    "\n",
    "Voici 2 représentations possibles de la distribution de la variable categ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme en secteurs\n",
    "data[\"categ\"].value_counts(normalize=True).plot(kind='pie')\n",
    "# Cette ligne assure que le pie chart est un cercle plutôt qu'une éllipse\n",
    "plt.axis('equal') \n",
    "plt.show() # Affiche le graphique\n",
    "\n",
    "# Diagramme en tuyaux d'orgues\n",
    "data[\"categ\"].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À gauche, vous avez le diagramme en secteurs, plus connu sous le nom de diagramme en camembert. Si les francophones y voient un camembert (fleuron de la gastronomie française), les anglophones y voient plutôt une tarte, et l'appellent donc **pie chart**. Ici, l'angle de chaque secteur est proportionnel à l'effectif de chaque modalité.\n",
    "\n",
    "À droite, c'est le diagramme en tuyaux d'orgue, appelé en anglais **bar chart**. La hauteur des tuyaux est égale à l'effectif de chaque modalité, ou bien (au choix) égale à la fréquence de chaque modalité, comme c'est le cas ici.\n",
    "\n",
    "**2. Variables quantitatives**\n",
    "\n",
    "Pour les **variables discrètes**, on les représente par un équivalent du diagramme en tuyaux d'orgue : **le diagramme en bâtons**. Cependant, avec les variables qualitatives, on pouvait placer les tuyaux un peu n'importe où sur l'axe horizontal. Mais avec une variable quantitative, on est contraint à placer précisément les bâtons sur l'axe horizontal. Comme on doit être précis, on préfère que les bâtons soient très fins. \n",
    "\n",
    "Pour représenter cela, nous allons créer une variable `quart_mois` pouvant prendre les valeurs 1, 2, 3 ou 4, et indiquant l'avancée dans le mois (1 : début, ..., 4 : fin de mois) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quart_mois'] = [int((jour-1)*4/31)+1 for jour in data[\"date_operation\"].dt.day]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent représenter sa distribution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme en bâtons\n",
    "data[\"quart_mois\"].value_counts(normalize=True).plot(kind='bar',width=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables **continues**, on utilise l'histogramme, dans lequel les valeurs sont agrégées. Ici, comme on représente des classes (ou des intervalles, si vous préférez), on n'utilise plus de fins bâtons, mais des rectangles dont la largeur correspond à la largeur de la classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme\n",
    "data[\"montant\"].hist(density=True)\n",
    "plt.show()\n",
    "\n",
    "# Histogramme plus beau\n",
    "data[data.montant.abs() < 100][\"montant\"].hist(density=True,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C4\"> P3C2 - Présentez une variable sous forme de tableau</a>\n",
    "\n",
    "Voici le code qui a généré le tableau récapitulatif de la variable quart_mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effectifs = data[\"quart_mois\"].value_counts()\n",
    "modalites = effectifs.index # l'index de effectifs contient les modalités\n",
    "\n",
    "tab = pd.DataFrame(modalites, columns = [\"quart_mois\"]) # création du tableau à partir des modalités\n",
    "tab[\"n\"] = effectifs.values\n",
    "tab[\"f\"] = tab[\"n\"] / len(data) # len(data) renvoie la taille de l'échantillon\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer les fréquences cumulées, il suffit de 2 lignes en plus. L'une trie les valeurs, et l'autre calcule la somme cumulée des fréquences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab.sort_values(\"quart_mois\") # tri des valeurs de la variable X (croissant)\n",
    "tab[\"F\"] = tab[\"f\"].cumsum() # cumsum calcule la somme cumulée\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C5\"> P3C4 - Découvrez les mesures de tendance centrale</a>\n",
    "\n",
    "En Python, le calcul du mode tient en une ligne. Voici un exemple avec la variable montant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici comment calculer la moyenne des montants dépensés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà comment calculer la médiane des montants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons un peu plus en détail notre variable montant.\n",
    "\n",
    "Les montants des opérations sont très hétérogènes : il y a des dépenses (à montant négatif) parfois grosses (les loyers, par exemple), souvent petites (courses, téléphone, etc.), et il y a des rentrées d'argent (à montant positif), peu fréquentes mais grosses. Difficile donc d'interpréter la moyenne (très sensible aux valeurs atypiques) qui vaut ici 2,87 €.\n",
    "\n",
    "On a le même problème pour la médiane qui vaut -9,6 €. Le fait qu'elle soit négative nous indique cependant qu'il y a plus de dépenses que d'entrées d'argent. Par contre, le mode nous indique que la plupart des opérations tournent autour de -1,6 €. Ici, les 3 mesures sont très éloignées les unes des autres.\n",
    "\n",
    "Pour avoir des montants d'opérations plus homogènes, il serait intéressant de calculer ces mesures pour chaque catégorie d'opération : les montants devraient être moins éparpillés au sein d'une catégorie puisque les opérations sont de même nature. Je vous laisse le faire en Python. Vous pouvez réaliser cela via une boucle `for`, qui itérera sur chacune des catégories. Ne vous arrêtez cependant pas uniquement au code, essayez d'en tirer une dimension analytique : quelle interprétation pouvez-vous faire des résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in data[\"categ\"].unique():\n",
    "    subset = data.loc[data.categ == cat, :] # Création du sous-échantillon\n",
    "    print(\"-\"*20)\n",
    "    print(cat)\n",
    "    print(\"moy:\\n\",subset['montant'].mean())\n",
    "    print(\"med:\\n\",subset['montant'].median())\n",
    "    print(\"mod:\\n\",subset['montant'].mode())\n",
    "    subset[\"montant\"].hist() # Crée l'histogramme\n",
    "    plt.show() # Affiche l'histogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque catégorie, on crée un sous-échantillon (subset) qui contient uniquement les opérations de la catégorie en cours. On affiche en lignes 5 à 7 les 3 mesures, et on affiche également l'histogramme pour mettre en perspectives les 3 mesures. A vous d'interpréter vos résultats !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C6\">P3C5 - Comprenez les mesures de dispersion</a>\n",
    "\n",
    "Pour calculer la variance en Python, cela se fait très facilement ! Il suffit d'utiliser la méthode .var() sur la variable considérée. Par exemple avec la variable montant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aussi, vous trouverez souvent une version \"corrigée\" de la variance empirique, que l'on qualifie de non biaisée. En effet, quand on se plonge dans les calculs, on s'aperçoit que la variance empirique donne des valeurs qui (en moyenne) sont inférieures à la variance de la variable aléatoire. Il s'agit de la notion de biais d'un estimateur. Un estimateur sans biais est meilleur qu'un estimateur biaisé.\n",
    "\n",
    "Pour corriger ce biais, on a créé la variance empirique corrigée, ou variance empirique sans biais. Voici comment calculer la variance empirique corrigée en Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].var(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà comment calculer l'écart-type de la variable montant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais lorsque vous faites un trajet, un écart-type de 6,55 minutes sur un trajet de 1 h (1h en moyenne), ce n'est pas la même chose qu'un écart-type de 6,55 minutes sur un trajet de 24 h (24h en moyenne) ! Pour remédier à cela, on a donc créé le coefficient de variation qui est l'écart-type empirique divisé par la moyenne.\n",
    "\n",
    "Le calcul de ce dernier en Python est tout aussi simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons facilement construire une boîte à moustaches avec Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column=\"montant\", vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À votre tour ! Reprenez le code développé lors du chapitre précédent, en y ajoutant pour chaque catégorie :\n",
    "- l'écart-type ;\n",
    "- la variance ;\n",
    "- un histogramme ;\n",
    "- une boîte à moustache des montants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in data[\"categ\"].unique():\n",
    "    subset = data[data.categ == cat]\n",
    "    print(\"-\"*20)\n",
    "    print(cat)\n",
    "    print(\"moy:\\n\",subset['montant'].mean())\n",
    "    print(\"med:\\n\",subset['montant'].median())\n",
    "    print(\"mod:\\n\",subset['montant'].mode())\n",
    "    print(\"var:\\n\",subset['montant'].var(ddof=0))\n",
    "    print(\"ect:\\n\",subset['montant'].std(ddof=0))\n",
    "    subset[\"montant\"].hist()\n",
    "    plt.show()\n",
    "    subset.boxplot(column=\"montant\", vert=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La variance du montant des opérations de la catégorie LOYER est nulle, ce qui signifie que le montant du loyer est toujours resté fixe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C7\"> P3C6 - Appréhendez les mesures de forme</a>\n",
    "\n",
    "Le calcul du skewness se fait très facilement en Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà comment calculer le kurtosis de notre variable montant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['montant'].kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poussez encore votre analyse un peu plus loin ! Ajoutez le calcul du Skewness empirique et le Kurtosis empirique pour chaque catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in data[\"categ\"].unique():\n",
    "    subset = data[data.categ == cat]\n",
    "    print(\"-\"*20)\n",
    "    print(cat)\n",
    "    print(\"moy:\\n\",subset['montant'].mean())\n",
    "    print(\"med:\\n\",subset['montant'].median())\n",
    "    print(\"mod:\\n\",subset['montant'].mode())\n",
    "    print(\"var:\\n\",subset['montant'].var(ddof=0))\n",
    "    print(\"ect:\\n\",subset['montant'].std(ddof=0))\n",
    "    print(\"skw:\\n\",subset['montant'].skew())\n",
    "    print(\"kur:\\n\",subset['montant'].kurtosis())\n",
    "    subset[\"montant\"].hist()\n",
    "    plt.show()\n",
    "    subset.boxplot(column=\"montant\", vert=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour toutes les opérations dont la catégorie regroupe principalement des dépenses (téléphone, courses, etc.), il est assez normal que le skewness empirique soit négatif. La distribution des dépenses s'étale vers la gauche, car on fait fréquemment des petites dépenses, et moins souvent des dépenses qui parfois peuvent être très importantes (donc très à gauche)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C8\">P3C7 - Familiarisez-vous avec les mesures de concentration</a>\n",
    "\n",
    "Voici le code permettant d'afficher la courbe de Lorenz :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depenses = data[data['montant'] < 0]\n",
    "dep = -depenses['montant'].values\n",
    "n = len(dep)\n",
    "lorenz = np.cumsum(np.sort(dep)) / dep.sum()\n",
    "lorenz = np.append([0],lorenz) # La courbe de Lorenz commence à 0\n",
    "\n",
    "xaxis = np.linspace(0-1/n,1+1/n,len(lorenz)) #Il y a un segment de taille n pour chaque individu, plus 1 segment supplémentaire d'ordonnée 0. Le premier segment commence à 0-1/n, et le dernier termine à 1+1/n.\n",
    "plt.plot(xaxis,lorenz,drawstyle='steps-post')\n",
    "plt.plot([0,1], [0,1]) #tracer la bisséctrice\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On y sélectionne tout d'abord le sous-échantillon de travail que l'on appelle  depenses  . Comme évoqué plus haut, il faut trier les individus dans l'ordre croissant des valeurs de la variable ; nous le faisons ici grâce à `np.sort(dep)`, car  dep  contient les observations de la variable montant.\n",
    "\n",
    "Ensuite, nous calculons la somme cumulée grâce à  `np.cumsum()`. Pour normaliser et faire en sorte que le haut de la courbe soit à 1, on divise le tout par  `dep.sum()`. La variable  lorenz  contient les ordonnées des points, mais il nous faut maintenant leurs abscisses : celles-ci s'étendent de 0 à 1 (comme évoqué précédemment) à intervalle réguliers. C'est ce que produit  `np.linspace(0-1/n,1+1/n,len(lorenz))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul de l'indice de Gini reprend directement les variables issues du traçage de la courbe de Lorenz mais est un peu plus complexe à comprendre, je laisse les plus courageux s'y plonger ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = (lorenz.sum() -lorenz[-1]/2 -lorenz[0]/2)/n # Surface sous la courbe de Lorenz. Le premier segment (lorenz[0]) est à moitié en dessous de 0, on le coupe donc en 2, on fait de même pour le dernier segment lorenz[-1] qui est à moitié au dessus de 1.\n",
    "S = 0.5 - AUC # surface entre la première bissectrice et le courbe de Lorenz\n",
    "gini = 2*S\n",
    "gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C9\"> P4C3 - Analysez la corrélation entre deux variables quantitatives</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posons-nous la question suivante :\n",
    "\n",
    "    Êtes-vous moins dépensier lorsque vous avez peu d'argent sur votre compte ?\n",
    "\n",
    "Vous l'aurez deviné, les 2 variables à étudier sont : montant et solde_avt_operation. Rechercher une corrélation entre ces variables revient à dire : \"Sachant que le solde de votre compte est petit, peut-on s'attendre à ce que le montant de l'opération soit lui aussi petit ?\" (ou l'inverse).\n",
    "\n",
    "Je vous invite donc à tracer le diagramme de dispersion entre le solde avant opération et le montant des dépenses, et analyser ce qui en ressort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depenses = data[data.montant < 0]\n",
    "plt.plot(depenses[\"solde_avt_ope\"],-depenses[\"montant\"],'o')\n",
    "plt.xlabel(\"solde avant opération\")\n",
    "plt.ylabel(\"montant de dépense\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori sur ce diagramme de dispersion, il ne semble pas que quand le solde est petit, les montants soient particulièrement petits. Il semble ne pas y avoir de corrélation. Mais vous en trouverez peut-être une dans vos propres relevés !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir une représentation plus efficace que le scatter plot, il est possible d'agréger la variable X en abscisse (axe horizontal) en différentes classes. Cela équivaut à \"découper\" au couteau le graphique précédent en tranches verticales. On représente ensuite pour chaque tranche une boîte à moustaches calculée à partir de tous les points présents dans la tranche. Voici donc le nouveau graphique obtenu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_classe = 500 # taille des classes pour la discrétisation\n",
    "\n",
    "groupes = [] # va recevoir les données agrégées à afficher\n",
    "\n",
    "# on calcule des tranches allant de 0 au solde maximum par paliers de taille taille_classe\n",
    "tranches = np.arange(0, max(depenses[\"solde_avt_ope\"]), taille_classe)\n",
    "tranches += taille_classe/2 # on décale les tranches d'une demi taille de classe\n",
    "indices = np.digitize(depenses[\"solde_avt_ope\"], tranches) # associe chaque solde à son numéro de classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, tr in enumerate(tranches): # pour chaque tranche, ind reçoit le numéro de tranche et tr la tranche en question\n",
    "    montants = -depenses.loc[indices==ind,\"montant\"] # sélection des individus de la tranche ind\n",
    "    if len(montants) > 0:\n",
    "        g = {\n",
    "            'valeurs': montants,\n",
    "            'centre_classe': tr-(taille_classe/2),\n",
    "            'taille': len(montants),\n",
    "            'quartiles': [np.percentile(montants,p) for p in [25,50,75]]\n",
    "        }\n",
    "        groupes.append(g)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "        \n",
    "# affichage des boxplots\n",
    "plt.boxplot([g[\"valeurs\"] for g in groupes],\n",
    "            positions= [g[\"centre_classe\"] for g in groupes], # abscisses des boxplots\n",
    "            showfliers= False, # on ne prend pas en compte les outliers\n",
    "            widths= taille_classe*0.7) # largeur graphique des boxplots\n",
    "\n",
    "# affichage des effectifs de chaque classe\n",
    "for g in groupes:\n",
    "    plt.text(g[\"centre_classe\"],0,\"(n={})\".format(g[\"taille\"]),horizontalalignment='center',verticalalignment='top')     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer le coefficient de Pearson et la covariance, 2 lignes suffisent !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.pearsonr(depenses[\"solde_avt_ope\"],-depenses[\"montant\"])[0])\n",
    "print(np.cov(depenses[\"solde_avt_ope\"],-depenses[\"montant\"],ddof=0)[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C10\"> P4C4 - Analysez deux variables quantitatives par régression linéaire</a>\n",
    "\n",
    "Tout d'abord, il faut calculer la variable attente ! Voici le code permettant de créer cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection du sous-échantillon\n",
    "courses = data.loc[data.categ == \"COURSES\", :]\n",
    "\n",
    "# On trie les opérations par date\n",
    "courses = courses.sort_values(\"date_operation\")\n",
    "\n",
    "# On ramène les montants en positif\n",
    "courses[\"montant\"] = -courses[\"montant\"]\n",
    "\n",
    "# calcul de la variable attente\n",
    "r = []\n",
    "last_date = dt.datetime.now()\n",
    "for i,row in courses.iterrows():\n",
    "    days = (row[\"date_operation\"]-last_date).days\n",
    "    if days == 0:\n",
    "        r.append(r[-1])\n",
    "    else:\n",
    "        r.append(days)\n",
    "    last_date = row[\"date_operation\"]\n",
    "courses[\"attente\"] = r\n",
    "courses = courses.iloc[1:,]\n",
    "\n",
    "# on regroupe les opérations qui ont été effectués à la même date\n",
    "# (courses réalisées le même jour mais dans 2 magasins différents)\n",
    "a = courses.groupby(\"date_operation\")[\"montant\"].sum()\n",
    "b = courses.groupby(\"date_operation\")[\"attente\"].first()\n",
    "courses = pd.DataFrame({\"montant\":a, \"attente\":b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici au final un sous-échantillon qui ne contient que les opérations de catégorie courses, et que l'on appelle...  courses  !\n",
    "\n",
    "Essayons d'afficher le diagramme de dispersion avec X = attente et Y = montant, et regardons si tous les points sont alignés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(courses['attente'],courses['montant'], \"o\")\n",
    "plt.xlabel(\"attente\")\n",
    "plt.ylabel(\"montant\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent effectuer notre régression linéaire. Voici comment estimer a et b avec Python. Le code est un peu complexe, mais retenez que la dernière ligne crée les variables  a  et  b  contenant les estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "Y = courses['montant']\n",
    "X = courses[['attente']]\n",
    "X = X.copy() # On modifiera X, on en crée donc une copie\n",
    "X['intercept'] = 1.\n",
    "result = sm.OLS(Y, X).fit() # OLS = Ordinary Least Square (Moindres Carrés Ordinaire)\n",
    "a,b = result.params['attente'],result.params['intercept']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici comment tracer la droite de régression à partir des coefficients obtenus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(courses.attente,courses.montant, \"o\")\n",
    "plt.plot(np.arange(15),[a*x+b for x in np.arange(15)])\n",
    "plt.xlabel(\"attente\")\n",
    "plt.ylabel(\"montant\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Régression linéaire sans les outliers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = courses.loc[courses['attente'] < 15, :]\n",
    "\n",
    "Y = courses['montant']\n",
    "X = courses[['attente']]\n",
    "X = X.copy() # On modifiera X, on en crée donc une copie\n",
    "X['intercept'] = 1.\n",
    "result = sm.OLS(Y, X).fit() # OLS = Ordinary Least Square (Moindres Carrés Ordinaire)\n",
    "a_new,b_new = result.params['attente'],result.params['intercept']\n",
    "\n",
    "print(result.params)\n",
    "\n",
    "plt.plot(courses.attente,courses.montant, \"o\")\n",
    "plt.plot(np.arange(15),[a_new*x+b_new for x in np.arange(15)])\n",
    "plt.plot(np.arange(15),[a*x+b for x in np.arange(15)])\n",
    "plt.xlabel(\"attente\")\n",
    "plt.ylabel(\"montant\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C11\"> P4C5 - Analysez une variable quantitative et une qualitative par ANOVA</a>\n",
    "\n",
    "Voici le code qui permet de représenter une variable quantitative et une variable qualitative. Tout d'abord, créez le sous-échantillon sur lequel vous souhaitez travailler en adaptant ce code, notamment les variables X et Y selon la question que vous aurez choisie parmi celles ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"categ\" # qualitative\n",
    "Y = \"montant\" # quantitative\n",
    "\n",
    "# On ne garde que les dépenses\n",
    "sous_echantillon = data.loc[data[\"montant\"] < 0, :].copy()\n",
    "# On remet les dépenses en positif\n",
    "sous_echantillon[\"montant\"] = -sous_echantillon[\"montant\"]\n",
    "# On n'étudie pas les loyers car trop gros:\n",
    "sous_echantillon = sous_echantillon.loc[sous_echantillon[\"categ\"] != \"LOYER\", :] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, ces quelques lignes de code affichent votre graphique !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalites = sous_echantillon[X].unique()\n",
    "groupes = []\n",
    "for m in modalites:\n",
    "    groupes.append(sous_echantillon[sous_echantillon[X]==m][Y])\n",
    "\n",
    "# Propriétés graphiques (pas très importantes)    \n",
    "medianprops = {'color':\"black\"}\n",
    "meanprops = {'marker':'o', 'markeredgecolor':'black',\n",
    "            'markerfacecolor':'firebrick'}\n",
    "    \n",
    "plt.boxplot(groupes, labels=modalites, showfliers=False, medianprops=medianprops, \n",
    "            vert=False, patch_artist=True, showmeans=True, meanprops=meanprops)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les points rouges au milieu de chaque boîte à moustaches représentent la moyenne des valeurs.\n",
    "\n",
    "On voit ici que les montants sont très différents d'une catégorie à l'autre. Par exemple, les montants des dépenses de transport sont plus élevés et plus dispersés que ceux des factures téléphoniques. Mais vérifions maintenant cette affirmation par les chiffres, grâce à une modélisation.\n",
    "\n",
    "Voici à présent le code permettant de calculer $\\eta^2$ (eta carré ou eta squared, en anglais). Je vous propose ici de faire le calcul à la main ;) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"categ\" # qualitative\n",
    "Y = \"montant\" # quantitative\n",
    "\n",
    "def eta_squared(x,y):\n",
    "    moyenne_y = y.mean()\n",
    "    classes = []\n",
    "    for classe in x.unique():\n",
    "        yi_classe = y[x==classe]\n",
    "        classes.append({'ni': len(yi_classe),\n",
    "                        'moyenne_classe': yi_classe.mean()})\n",
    "    SCT = sum([(yj-moyenne_y)**2 for yj in y])\n",
    "    SCE = sum([c['ni']*(c['moyenne_classe']-moyenne_y)**2 for c in classes])\n",
    "    return SCE/SCT\n",
    "    \n",
    "eta_squared(sous_echantillon[X],sous_echantillon[Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va aller plus loin en analysant la corrélation entre la variable quart_mois créée précédemment et le montant des achats. En effet, il serait intéressant de déterminer si certains jours sont plus \"propices\" à la dépense que d'autres et pourquoi pas, essayer de dégager les raisons !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"quart_mois\" # qualitative\n",
    "Y = \"montant\" # quantitative\n",
    "\n",
    "modalites = sous_echantillon[X].unique()\n",
    "groupes = []\n",
    "for m in modalites:\n",
    "    groupes.append(sous_echantillon[sous_echantillon[X]==m][Y])\n",
    "\n",
    "# Propriétés graphiques (pas très importantes)    \n",
    "medianprops = {'color':\"black\"}\n",
    "meanprops = {'marker':'o', 'markeredgecolor':'black',\n",
    "            'markerfacecolor':'firebrick'}\n",
    "    \n",
    "plt.boxplot(groupes, labels=modalites, showfliers=False, medianprops=medianprops, \n",
    "            vert=False, patch_artist=True, showmeans=True, meanprops=meanprops)\n",
    "plt.show()\n",
    "\n",
    "eta_squared(sous_echantillon[X],sous_echantillon[Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"C12\"> P4C6 - Analysez deux variables qualitatives avec le Chi-2</a>\n",
    "\n",
    "Pour répondre à ces questions, vous pouvez afficher le tableau de contingence comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"quart_mois\"\n",
    "Y = \"categ\"\n",
    "\n",
    "cont = data[[X,Y]].pivot_table(index=X,columns=Y,aggfunc=len,margins=True,margins_name=\"Total\")\n",
    "cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code affichant cette heatmap :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tx = cont.loc[:,[\"Total\"]]\n",
    "ty = cont.loc[[\"Total\"],:]\n",
    "n = len(data)\n",
    "indep = tx.dot(ty) / n\n",
    "\n",
    "c = cont.fillna(0) # On remplace les valeurs nulles par 0\n",
    "measure = (c-indep)**2/indep\n",
    "xi_n = measure.sum().sum()\n",
    "table = measure/xi_n\n",
    "sns.heatmap(table.iloc[:-1,:-1],annot=c.iloc[:-1,:-1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('OC_library')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f43c9b916d3b44a8b7c02f385ad4db6e8dcb5cb089487eeac82ee13e9872666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
